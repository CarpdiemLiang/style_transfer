{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 4                             \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/photo2ukiyoe       \n",
      "             dataset_mode: single                        \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "                     eval: False                         \n",
      "                        f: /datasets/home/home-02/64/064/t5yu/.local/share/jupyter/runtime/kernel-1231469d-56bd-4717-b664-a7a7419c4a2b.json\t[default: None]\n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: kaiming                       \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: test                          \n",
      "             model_suffix: _A                            \n",
      "               n_layers_D: 3                             \n",
      "                     name: photo2ukiyoe_kaiming_dropout  \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: instance                      \n",
      "                    ntest: inf                           \n",
      "                 num_test: 20                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [SingleDataset] was created\n",
      "initialize network with kaiming\n",
      "model [TestModel] was created\n",
      "loading the model from ./checkpoints/photo2ukiyoe_kaiming_dropout/latest_net_G_A.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.378 M\n",
      "-----------------------------------------------\n",
      "processing (0000)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.0_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0002)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.10_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0004)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.11_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0006)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.12_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0008)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.13_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0010)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.14_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0012)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.15_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0014)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.16_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0016)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.17_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing (0018)-th image... ['./datasets/photo2ukiyoe/results_kaiming_init/No.18_fake_B.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ntpath\n",
    "import torch\n",
    "from util import util\n",
    "from options.test_options import TestOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def myImshow(image, ax):\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    opt = TestOptions().parse()  # get test options\n",
    "    # hard-code some parameters for test\n",
    "    opt.num_threads = 1   # test code only supports num_threads = 1\n",
    "    opt.batch_size = 1    # test code only supports batch_size = 1\n",
    "    opt.serial_batches = True  # disable data shuffling; comment this line if results on randomly chosen images are needed.\n",
    "    opt.no_flip = True    # no flip; comment this line if results on flipped images are needed.\n",
    "    opt.no_dropout = True   # need to delete dropout here to avoid network structure disalign\n",
    "    opt.display_id = -1   # no visdom display; the test code saves the results to a HTML file.\n",
    "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "    #print(len(dataset))\n",
    "    model = create_model(opt)      # create a model given opt.model and other options\n",
    "    #model = torch.nn.DataParallel(model)\n",
    "    #cudnn.benchmark = True\n",
    "    model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "    # test with eval mode. This only affects layers like batchnorm and dropout.\n",
    "    # For [pix2pix]: we use batchnorm and dropout in the original pix2pix. You can experiment it with and without eval() mode.\n",
    "    # For [CycleGAN]: It should not affect CycleGAN as CycleGAN uses instancenorm without dropout.\n",
    "    if opt.eval:\n",
    "        model.eval()\n",
    "    for i, data in enumerate(dataset):\n",
    "        if i >= opt.num_test:  # only apply our model to opt.num_test images.\n",
    "            break\n",
    "        model.set_input(data)  # unpack data from data loader\n",
    "        model.test()           # run inference\n",
    "        visuals = model.get_current_visuals()  # get image results\n",
    "        img_path = model.get_image_paths()     # get image paths\n",
    "        #img_path = './datasets/photo2ukiyoe'\n",
    "        if i % 2 == 0:\n",
    "            print('processing (%04d)-th image... %s' % (i, img_path))\n",
    "            ims = []\n",
    "            for l, im_data in visuals.items():\n",
    "                im = util.tensor2im(im_data)\n",
    "                ims.append(im)\n",
    "                #print(im_data.shape)\n",
    "                image_name = 'No.%s_%s.png' % (i, l)\n",
    "                save_path = './datasets/results/' + image_name\n",
    "                util.save_image(im, save_path)\n",
    "            fig, axes = plt.subplots(ncols=2, figsize=(7, 3))\n",
    "            myImshow(ims[0], axes[0])\n",
    "            myImshow(ims[1], axes[1])\n",
    "            plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
