{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 4                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: True                          \n",
      "                crop_size: 256                           \n",
      "                 dataroot: ./datasets/photo2ukiyoe       \n",
      "             dataset_mode: unaligned                     \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                        f: /datasets/home/home-02/64/064/t5yu/.local/share/jupyter/runtime/kernel-adf42c40-b6f6-4348-9964-d04cf0a7c13f.json\t[default: None]\n",
      "                 gan_mode: lsgan                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: kaiming                       \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                 lambda_A: 10.0                          \n",
      "                 lambda_B: 10.0                          \n",
      "          lambda_identity: 0.5                           \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 288                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: cycle_gan                     \n",
      "               n_layers_D: 3                             \n",
      "                     name: photo2ukiyoe_kaiming_dropout  \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: resnet_9blocks                \n",
      "                      ngf: 64                            \n",
      "                    niter: 1                             \n",
      "              niter_decay: 1                             \n",
      "               no_dropout: True                          \n",
      "                  no_flip: False                         \n",
      "                  no_html: True                          \n",
      "                     norm: instance                      \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 400                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 10                            \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [UnalignedDataset] was created\n",
      "The number of training images = 400\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "initialize network with kaiming\n",
      "model [CycleGANModel] was created\n",
      "loading the model from ./checkpoints/photo2ukiyoe_kaiming_dropout/latest_net_G_A.pth\n",
      "loading the model from ./checkpoints/photo2ukiyoe_kaiming_dropout/latest_net_G_B.pth\n",
      "loading the model from ./checkpoints/photo2ukiyoe_kaiming_dropout/latest_net_D_A.pth\n",
      "loading the model from ./checkpoints/photo2ukiyoe_kaiming_dropout/latest_net_D_B.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G_A] Total number of parameters : 11.378 M\n",
      "[Network G_B] Total number of parameters : 11.378 M\n",
      "[Network D_A] Total number of parameters : 2.765 M\n",
      "[Network D_B] Total number of parameters : 2.765 M\n",
      "-----------------------------------------------\n",
      "(epoch: 1, iters: 400, time: 0.432, data: 0.343) D_A: 0.160 G_A: 0.752 cycle_A: 0.986 idt_A: 0.481 D_B: 0.098 G_B: 0.394 cycle_B: 1.211 idt_B: 0.362 \n",
      "End of epoch 1 / 2 \t Time Taken: 198 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 400, time: 0.314, data: 0.425) D_A: 0.192 G_A: 0.541 cycle_A: 1.179 idt_A: 0.460 D_B: 0.249 G_B: 0.409 cycle_B: 1.284 idt_B: 0.405 \n",
      "End of epoch 2 / 2 \t Time Taken: 194 sec\n",
      "learning rate = 0.0001000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from options.train_options import TrainOptions\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    opt = TrainOptions().parse()   # get training options\n",
    "    dataset = create_dataset(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "    dataset_size = len(dataset)    # get the number of images in the dataset.\n",
    "    print('The number of training images = %d' % dataset_size)\n",
    "\n",
    "    model = create_model(opt)      # create a model given opt.model and other options\n",
    "    model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "    total_iters = 0                # the total number of training iterations\n",
    "    visualizer = Visualizer(opt)\n",
    "    \n",
    "    for epoch in range(opt.epoch_count, opt.niter + opt.niter_decay + 1):    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "        epoch_start_time = time.time()  # timer for entire epoch\n",
    "        iter_data_time = time.time()    # timer for data loading per iteration\n",
    "        epoch_iter = 0                  # the number of training iterations in current epoch, reset to 0 every epoch\n",
    "\n",
    "        for i, data in enumerate(dataset):  # inner loop within one epoch\n",
    "            iter_start_time = time.time()  # timer for computation per iteration\n",
    "            if total_iters % opt.print_freq == 0:\n",
    "                t_data = iter_start_time - iter_data_time\n",
    "            visualizer.reset()\n",
    "            total_iters += opt.batch_size\n",
    "            epoch_iter += opt.batch_size\n",
    "            model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "            model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "\n",
    "            if total_iters % opt.print_freq == 0:    # print training losses and save logging information to the disk\n",
    "                losses = model.get_current_losses()\n",
    "                t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
    "                visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "        if epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "            print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "            model.save_networks('latest')\n",
    "            model.save_networks(epoch)\n",
    "\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "        model.update_learning_rate()                     # update learning rates at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
